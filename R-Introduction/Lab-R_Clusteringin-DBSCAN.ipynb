{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DBSCAN: Density-Based Clustering \n",
    "\n",
    "See https://www.datanovia.com/en/lessons/dbscan-density-based-clustering-essentials/\n",
    "\n",
    "DBSCAN (Density-Based Spatial Clustering and Application with Noise), is a density-based clusering algorithm (Ester et al. 1996), which can be used to identify clusters of any shape in a data set containing noise and outliers.\n",
    "\n",
    "The basic idea behind the density-based clustering approach is derived from a human intuitive clustering method. For instance, by looking at the figure below, one can easily identify four clusters along with several points of noise, because of the differences in the density of points.\n",
    "\n",
    "Clusters are dense regions in the data space, separated by regions of lower density of points. The DBSCAN algorithm is based on this intuitive notion of “clusters” and “noise”. The key idea is that for each point of a cluster, the neighborhood of a given radius has to contain at least a minimum number of points.\n",
    "\n",
    "![dbscan-idea](https://www.datanovia.com/en/wp-content/uploads/dn-tutorials/005-advanced-clustering/images/dbscan-idea.png)\n",
    "\n",
    "DBSCAN idea (From Ester et al. 1996)\n",
    "\n",
    "\n",
    "## Why DBSCAN??\n",
    "\n",
    "Partitioning methods (K-means, PAM clustering) and hierarchical clustering are suitable for finding spherical-shaped clusters or convex clusters. In other words, they work well only for compact and well separated clusters. Moreover, they are also severely affected by the presence of noise and outliers in the data.\n",
    "\n",
    "Unfortunately, real life data can contain: i) clusters of arbitrary shape such as those shown in the figure below (oval, linear and “S” shape clusters); ii) many outliers and noise.\n",
    "\n",
    "The figure below shows a data set containing nonconvex clusters and outliers/noises. The simulated data set multishapes [in factoextra package] is used.\n",
    "\n",
    "![Data](https://www.datanovia.com/en/wp-content/uploads/dn-tutorials/005-advanced-clustering/figures/023-dbscan-density-based-clustering-data-dbscan-1.png)\n",
    "\n",
    "The plot above contains 5 clusters and outliers, including:\n",
    "\n",
    "*    2 ovales clusters\n",
    "*    2 linear clusters\n",
    "*    1 compact cluster\n",
    "\n",
    "Given such data, k-means algorithm has difficulties for identifying theses clusters with arbitrary shapes. To illustrate this situation, the following R code computes k-means algorithm on the multishapes data set. The function fviz_cluster()[factoextra package] is used to visualize the clusters.\n",
    "\n",
    "First, install factoextra: install.packages(“factoextra”); then compute and visualize k-means clustering using the data set multishapes:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Installing packages into ‘/home/iserina/R/x86_64-pc-linux-gnu-library/3.5’\n",
      "(as ‘lib’ is unspecified)\n",
      "also installing the dependencies ‘ellipse’, ‘flashClust’, ‘leaps’, ‘ggsci’, ‘cowplot’, ‘ggsignif’, ‘polynom’, ‘flexmix’, ‘prabclus’, ‘diptest’, ‘mvtnorm’, ‘robustbase’, ‘kernlab’, ‘trimcluster’, ‘dendextend’, ‘FactoMineR’, ‘ggpubr’\n",
      "\n",
      "Warning message in install.packages(new.packages):\n",
      "“installation of package ‘prabclus’ had non-zero exit status”Warning message in install.packages(new.packages):\n",
      "“installation of package ‘fpc’ had non-zero exit status”Warning message in install.packages(new.packages):\n",
      "“installation of package ‘dendextend’ had non-zero exit status”Warning message in install.packages(new.packages):\n",
      "“installation of package ‘factoextra’ had non-zero exit status”"
     ]
    }
   ],
   "source": [
    "list.of.packages <- c(\"fpc\",\"dbscan\",\"factoextra\")\n",
    "new.packages <- list.of.packages[!(list.of.packages %in% installed.packages()[,\"Package\"])]\n",
    "if(length(new.packages)) install.packages(new.packages)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in library(factoextra): there is no package called ‘factoextra’\n",
     "output_type": "error",
     "traceback": [
      "Error in library(factoextra): there is no package called ‘factoextra’\nTraceback:\n",
      "1. library(factoextra)",
      "2. stop(txt, domain = NA)"
     ]
    }
   ],
   "source": [
    "library(factoextra)\n",
    "data(\"multishapes\")\n",
    "df <- multishapes[, 1:2]\n",
    "set.seed(123)\n",
    "km.res <- kmeans(df, 5, nstart = 25)\n",
    "fviz_cluster(km.res, df,  geom = \"point\", \n",
    "             ellipse= FALSE, show.clust.cent = FALSE,\n",
    "             palette = \"jco\", ggtheme = theme_classic())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing DBSCAN\n",
    "\n",
    "Here, we’ll use the R package fpc to compute DBSCAN. It’s also possible to use the package dbscan, which provides a faster re-implementation of DBSCAN algorithm compared to the fpc package.\n",
    "\n",
    "We’ll also use the factoextra package for visualizing clusters.\n",
    "\n",
    "The R code below computes and visualizes DBSCAN using multishapes data set [factoextra R package]:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data \n",
    "data(\"multishapes\", package = \"factoextra\")\n",
    "df <- multishapes[, 1:2]\n",
    "\n",
    "# Compute DBSCAN using fpc package\n",
    "library(\"fpc\")\n",
    "set.seed(123)\n",
    "db <- fpc::dbscan(df, eps = 0.15, MinPts = 5)\n",
    "\n",
    "# Plot DBSCAN results\n",
    "library(\"factoextra\")\n",
    "fviz_cluster(db, data = df, stand = FALSE,\n",
    "             ellipse = FALSE, show.clust.cent = FALSE,\n",
    "             geom = \"point\",palette = \"jco\", ggtheme = theme_classic())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Note that, the function fviz_cluster() uses different point symbols for core points (i.e, seed points) and border points. Black points correspond to outliers. You can play with eps and MinPts for changing cluster configurations.\n",
    "\n",
    "It can be seen that DBSCAN performs better for these data sets and can identify the correct set of clusters compared to k-means algorithms.\n",
    "\n",
    "The result of the fpc::dbscan() function can be displayed as follow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(db)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the table above, column names are cluster number. Cluster 0 corresponds to outliers (black points in the DBSCAN plot). The function print.dbscan() shows a statistic of the number of points belonging to the clusters that are seeds and border points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cluster membership. Noise/outlier observations are coded as 0\n",
    "# A random subset is shown\n",
    "db$cluster[sample(1:1089, 20)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DBSCAN algorithm requires users to specify the optimal eps values and the parameter MinPts. In the R code above, we used eps = 0.15 and MinPts = 5. One limitation of DBSCAN is that it is sensitive to the choice of ϵ, in particular if clusters have different densities. If ϵ is too small, sparser clusters will be defined as noise. If ϵ is too large, denser clusters may be merged together. This implies that, if there are clusters with different local densities, then a single ϵ\n",
    "\n",
    "value may not suffice.\n",
    "\n",
    "A natural question is:\n",
    "\n",
    "How to define the optimal value of ?\n",
    "\n",
    "## Method for determining the optimal eps value\n",
    "\n",
    "The method proposed here consists of computing the k-nearest neighbor distances in a matrix of points.\n",
    "\n",
    "The idea is to calculate, the average of the distances of every point to its k nearest neighbors. The value of k will be specified by the user and corresponds to MinPts.\n",
    "\n",
    "Next, these k-distances are plotted in an ascending order. The aim is to determine the “knee”, which corresponds to the optimal eps parameter.\n",
    "\n",
    "A knee corresponds to a threshold where a sharp change occurs along the k-distance curve.\n",
    "\n",
    "The function kNNdistplot() [in dbscan package] can be used to draw the k-distance plot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbscan::kNNdistplot(df, k =  5)\n",
    "abline(h = 0.15, lty = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "It can be seen that the optimal eps value is around a distance of 0.15.\n",
    "## Cluster predictions with DBSCAN algorithm\n",
    "\n",
    "The function predict.dbscan(object, data, newdata) [in fpc package] can be used to predict the clusters for the points in newdata. For more details, read the documentation (?predict.dbscan).\n",
    "\n",
    "#References\n",
    "\n",
    "Ester, Martin, Hans-Peter Kriegel, Jörg Sander, and Xiaowei Xu. 1996. “A Density-Based Algorithm for Discovering Clusters in Large Spatial Databases with Noise.” In, 226–31. AAAI Press.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
